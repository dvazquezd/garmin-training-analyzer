# Feature: Interfaz de L√≠nea de Comandos (CLI)

## Context
**Por qu√© existe**: Los usuarios necesitan ejecutar el an√°lisis con diferentes configuraciones sin editar archivos `.env`. Una CLI robusta permite automatizaci√≥n (cron jobs, CI/CD), scripting y uso flexible. Los argumentos CLI deben override configuraciones de `.env` para m√°xima flexibilidad.

**Valor que aporta**:
- Ejecuci√≥n flexible sin editar configuraci√≥n
- Automatizaci√≥n con scripts/cron
- Override r√°pido de par√°metros
- Help integrado (documentaci√≥n CLI)
- Validaci√≥n de argumentos
- Dry-run mode para testing

---

## User Story
**Como** usuario que ejecuta an√°lisis frecuentemente  
**Quiero** controlar todas las opciones desde la l√≠nea de comandos  
**Para** automatizar tareas y experimentar r√°pidamente sin editar archivos

---

## Acceptance Criteria

### Scenario 1: Mostrar help completo
**Given** el usuario ejecuta:
```bash
python training_analyzer.py --help
```
**When** el sistema procesa el comando  
**Then** muestra documentaci√≥n completa:
```
usage: training_analyzer.py [-h] [--days DAYS] [--provider PROVIDER]
                            [--model MODEL] [--email EMAIL]
                            [--password PASSWORD] [--no-cache]
                            [--clear-cache] [--export-all-formats]
                            [--debug] [--version]

üèÉ Garmin Training Analyzer - AI-powered training analysis

optional arguments:
  -h, --help            show this help message and exit

Analysis Options:
  --days DAYS           Days to analyze (default: 30)
  --provider PROVIDER   LLM provider: anthropic|openai|google
  --model MODEL         LLM model name
  --max-tokens TOKENS   Maximum tokens for analysis (default: 3000)
  --temperature TEMP    LLM temperature 0.0-1.0 (default: 0.7)

Garmin Authentication:
  --email EMAIL         Garmin email (overrides .env)
  --password PASSWORD   Garmin password (overrides .env)

Cache Options:
  --no-cache            Disable cache (force fresh API calls)
  --clear-cache         Clear all cached data before running
  --cache-ttl HOURS     Cache TTL in hours (default: 24)

Export Options:
  --export-all-formats  Export in TXT, MD, JSON, CSV
  --export-html-only    Export only HTML report
  --no-export           Skip file export (analysis only)

Debug & Info:
  --debug               Enable debug logging
  --verbose, -v         Verbose output
  --quiet, -q           Minimal output
  --version             Show version and exit
  --estimate-cost       Estimate API cost without executing

Examples:
  # Analyze last 60 days with Claude
  python training_analyzer.py --days 60 --provider anthropic

  # Use GPT-4 with custom credentials
  python training_analyzer.py --provider openai --email user@example.com

  # Clear cache and run fresh analysis
  python training_analyzer.py --clear-cache --days 30

For more info: https://github.com/dvazquezd/garmin-training-analyzer
```
**And** termina con c√≥digo de salida `0`

---

### Scenario 2: Override de d√≠as de an√°lisis
**Given** el `.env` tiene `ANALYSIS_DAYS=30`  
**When** ejecuta:
```bash
python training_analyzer.py --days 60
```
**Then** usa 60 d√≠as (no 30 del `.env`)  
**And** registra: `"‚öôÔ∏è  Usando 60 d√≠as de an√°lisis (override CLI)"`  
**And** el an√°lisis cubre los √∫ltimos 60 d√≠as

---

### Scenario 3: Override de proveedor LLM
**Given** el `.env` tiene `LLM_PROVIDER=anthropic`  
**When** ejecuta:
```bash
python training_analyzer.py --provider openai --model gpt-4o
```
**Then** usa OpenAI con GPT-4o (ignora Anthropic del `.env`)  
**And** registra: `"‚öôÔ∏è  Proveedor LLM: openai (modelo: gpt-4o) - override CLI"`

---

### Scenario 4: Credenciales Garmin desde CLI
**Given** el usuario NO quiere guardar credenciales en `.env`  
**When** ejecuta:
```bash
python training_analyzer.py --email user@garmin.com --password mypass
```
**Then** usa esas credenciales para autenticaci√≥n  
**And** NO las guarda en disco  
**And** muestra warning:
```
‚ö†Ô∏è  Usando credenciales desde CLI
   Nota: Evita usar passwords en CLI (quedan en historial de shell)
   Recomendaci√≥n: Usa .env para mayor seguridad
```

---

### Scenario 5: Limpiar cache antes de ejecutar
**Given** existe cache con datos de hace 5 d√≠as  
**When** ejecuta:
```bash
python training_analyzer.py --clear-cache
```
**Then** elimina TODO el cache antes de iniciar an√°lisis  
**And** registra:
```
üóëÔ∏è  Limpiando cache...
   Entradas eliminadas: 23
   Espacio liberado: 1.2 MB
‚úÖ Cache limpiado
```
**And** luego ejecuta an√°lisis normal (con fetch desde API)

---

### Scenario 6: Desactivar cache temporalmente
**Given** el `.env` tiene `USE_CACHE=true`  
**When** ejecuta:
```bash
python training_analyzer.py --no-cache
```
**Then** desactiva cache solo para esta ejecuci√≥n  
**And** hace todas las llamadas directas a API  
**And** NO guarda resultados en cache  
**And** registra: `"‚ö†Ô∏è  Cache desactivado para esta ejecuci√≥n"`

---

### Scenario 7: Modo debug verboso
**Given** el usuario quiere ver logs detallados  
**When** ejecuta:
```bash
python training_analyzer.py --debug
```
**Then** configura logging a nivel DEBUG  
**And** muestra logs detallados en consola:
```
[DEBUG] Loading config from .env
[DEBUG] Authenticating with Garmin (email: user@example.com)
[DEBUG] Cache hit: activities_30days_20250130
[DEBUG] LLM provider: anthropic, model: claude-sonnet-4
[DEBUG] Prompt tokens: 1,234
[DEBUG] Building HTML report...
```

---

### Scenario 8: Estimaci√≥n de coste sin ejecutar
**Given** el usuario quiere saber el coste antes de ejecutar  
**When** ejecuta:
```bash
python training_analyzer.py --days 60 --estimate-cost
```
**Then** calcula estimaci√≥n SIN llamar a LLM:
```
üìä Estimaci√≥n de Coste

Configuraci√≥n:
  - D√≠as de an√°lisis: 60
  - Proveedor: anthropic (claude-sonnet-4)
  - Actividades estimadas: ~25
  - Tokens input (est.): 5,200
  - Tokens output (max): 3,000

Coste estimado:
  - Input: $0.016 (5,200 tokens √ó $3/MTok)
  - Output: $0.045 (3,000 tokens √ó $15/MTok)
  - TOTAL: $0.061

¬øContinuar con el an√°lisis? (s/n):
```
**And** espera confirmaci√≥n del usuario  
**And** si responde "n", termina sin ejecutar

---

### Scenario 9: Modo silencioso (minimal output)
**Given** el usuario usa el script en automation  
**When** ejecuta:
```bash
python training_analyzer.py --quiet
```
**Then** solo muestra mensajes cr√≠ticos:
```
‚úÖ An√°lisis completado
üìÑ Reporte: analysis_reports/reporte_20250130_143022.html
```
**And** NO muestra progress bars, warnings no cr√≠ticos, ni debug  
**And** √∫til para logs limpios en CI/CD

---

### Scenario 10: Validaci√≥n de argumentos inv√°lidos
**Given** el usuario ejecuta con argumento inv√°lido:
```bash
python training_analyzer.py --days abc
```
**When** el sistema valida argumentos  
**Then** muestra error espec√≠fico:
```
‚ùå Error de validaci√≥n: Argumento '--days'
   Valor inv√°lido: 'abc'
   Esperado: N√∫mero entero positivo (1-365)
   
   Uso correcto:
     python training_analyzer.py --days 60
   
   Ver ayuda completa: python training_analyzer.py --help
```
**And** termina con c√≥digo de salida `2`  
**And** NO ejecuta el an√°lisis

---

### Scenario 11: Modo dry-run (simulaci√≥n)
**Given** el usuario quiere probar sin ejecutar realmente  
**When** ejecuta:
```bash
python training_analyzer.py --dry-run --days 60
```
**Then** simula la ejecuci√≥n sin hacer calls reales:
```
üîç Modo Dry-Run - Simulaci√≥n sin ejecuci√≥n real

Pasos a ejecutar:
  [1/5] ‚úì Autenticar con Garmin (user@example.com)
  [2/5] ‚úì Extraer actividades (√∫ltimos 60 d√≠as)
  [3/5] ‚úì Extraer composici√≥n corporal
  [4/5] ‚úì Generar an√°lisis con Claude Sonnet 4
  [5/5] ‚úì Exportar reporte HTML

Configuraci√≥n:
  - D√≠as: 60
  - Cache: Habilitado (TTL: 24h)
  - LLM: anthropic/claude-sonnet-4
  - Coste estimado: $0.061

‚ö†Ô∏è  Esta fue una simulaci√≥n. Usa sin --dry-run para ejecutar realmente.
```

---

### Scenario 12: Combinaci√≥n de m√∫ltiples flags
**Given** el usuario ejecuta con m√∫ltiples argumentos:
```bash
python training_analyzer.py \
  --days 90 \
  --provider anthropic \
  --model claude-opus-4-20251101 \
  --clear-cache \
  --export-all-formats \
  --debug
```
**When** el sistema procesa todos los argumentos  
**Then** aplica todos correctamente en orden de precedencia:
1. Limpia cache primero
2. Configura 90 d√≠as
3. Usa Claude Opus 4
4. Activa debug logging
5. Ejecuta an√°lisis
6. Exporta en todos los formatos
**And** cada paso se registra en debug log  
**And** NO hay conflictos entre flags

---

## Technical Notes
- **Librer√≠a**: `argparse` (stdlib Python) para parsing de argumentos
- **Precedencia**: CLI args > environment vars > defaults
- **Validaci√≥n**: Usar `type=` y `choices=` en argparse para validaci√≥n
- **Help formatting**: `formatter_class=argparse.RawDescriptionHelpFormatter`
- **Grupos de argumentos**: Agrupar args relacionados (Analysis, Cache, etc.)
- **Salida de error**: Stderr para errores, stdout para resultados
- **Exit codes**:
  - `0`: √âxito
  - `1`: Error de ejecuci√≥n
  - `2`: Error de argumentos
- **Seguridad**: NUNCA loguear passwords, incluso en debug mode

---

## Out of Scope
‚ùå GUI (Graphical User Interface)  
‚ùå TUI interactiva (textual/rich)  
‚ùå Configuraci√≥n interactiva (wizard)  
‚ùå Shell completion (bash/zsh autocomplete)  
‚ùå Subcomandos (e.g., `train analyze`, `train export`)  
‚ùå Alias de argumentos customizables

---

## Testing Strategy
```python
# tests/test_cli.py

import pytest
import sys
from unittest.mock import patch
from training_analyzer import main, parse_args

def test_help_flag_shows_documentation(capsys):
    """Scenario 1: Help"""
    with pytest.raises(SystemExit) as exc_info:
        parse_args(['--help'])
    
    assert exc_info.value.code == 0
    captured = capsys.readouterr()
    assert "Garmin Training Analyzer" in captured.out
    assert "--days" in captured.out

def test_days_override_from_cli():
    """Scenario 2: Days override"""
    args = parse_args(['--days', '60'])
    assert args.days == 60

def test_provider_override_from_cli():
    """Scenario 3: Provider override"""
    args = parse_args(['--provider', 'openai', '--model', 'gpt-4o'])
    assert args.provider == 'openai'
    assert args.model == 'gpt-4o'

def test_credentials_from_cli(caplog):
    """Scenario 4: CLI credentials"""
    args = parse_args(['--email', 'user@garmin.com', '--password', 'pass'])
    assert args.email == 'user@garmin.com'
    # Should show warning about CLI passwords

def test_clear_cache_flag():
    """Scenario 5: Clear cache"""
    args = parse_args(['--clear-cache'])
    assert args.clear_cache is True

def test_no_cache_flag():
    """Scenario 6: Disable cache"""
    args = parse_args(['--no-cache'])
    assert args.use_cache is False

def test_debug_flag_sets_logging():
    """Scenario 7: Debug mode"""
    with patch('logging.basicConfig') as mock_logging:
        args = parse_args(['--debug'])
        main(args)
        
        mock_logging.assert_called()
        # Verify DEBUG level was set

def test_estimate_cost_mode():
    """Scenario 8: Cost estimation"""
    with patch('builtins.input', return_value='n'):
        args = parse_args(['--estimate-cost'])
        result = main(args)
        
        # Should not execute analysis
        assert result['executed'] is False

def test_quiet_mode_minimal_output(capsys):
    """Scenario 9: Quiet mode"""
    args = parse_args(['--quiet'])
    main(args)
    
    captured = capsys.readouterr()
    # Should have minimal output
    assert len(captured.out.split('\n')) < 5

def test_invalid_days_argument():
    """Scenario 10: Validation"""
    with pytest.raises(SystemExit) as exc_info:
        parse_args(['--days', 'abc'])
    
    assert exc_info.value.code == 2

def test_dry_run_mode(caplog):
    """Scenario 11: Dry-run"""
    args = parse_args(['--dry-run', '--days', '60'])
    result = main(args)
    
    assert "Modo Dry-Run" in caplog.text
    assert result['dry_run'] is True
    # No API calls should be made

def test_multiple_flags_combination():
    """Scenario 12: Multiple flags"""
    args = parse_args([
        '--days', '90',
        '--provider', 'anthropic',
        '--clear-cache',
        '--export-all-formats',
        '--debug'
    ])
    
    assert args.days == 90
    assert args.provider == 'anthropic'
    assert args.clear_cache is True
    assert args.export_all_formats is True
    assert args.debug is True

def test_cli_precedence_over_env():
    """CLI should override environment variables"""
    with patch.dict('os.environ', {'ANALYSIS_DAYS': '30'}):
        args = parse_args(['--days', '60'])
        assert args.days == 60  # CLI wins
```

---

## Implementation Checklist
- [ ] Crear parser de argumentos en `training_analyzer.py`
- [ ] Implementar validaci√≥n de argumentos (tipos, rangos)
- [ ] A√±adir grupos de argumentos relacionados
- [ ] Implementar override de configuraci√≥n (.env < CLI)
- [ ] A√±adir modo `--estimate-cost`
- [ ] Implementar modo `--dry-run`
- [ ] A√±adir flags de verbosidad (`--debug`, `--quiet`)
- [ ] Implementar `--clear-cache` y `--no-cache`
- [ ] A√±adir help completo con ejemplos
- [ ] Implementar exit codes apropiados
- [ ] Crear tests en `tests/test_cli.py` (12 tests)
- [ ] Documentar CLI en README con ejemplos
- [ ] A√±adir secci√≥n de troubleshooting CLI

---

## Related Specs
- [Configuration](../00-configuration/config-management.spec.md) - CLI override config
- [Cache System](../03-caching/sqlite-cache.spec.md) - Flags --no-cache, --clear-cache
- [Multi-Format Reports](../05-reporting/multi-format-reports.spec.md) - Flags --export-*

---

## Changelog
- **2025-01-30**: Spec inicial creada con 12 escenarios
- **2025-01-30**: A√±adido Scenario 11 (dry-run) para testing seguro
- **2025-01-30**: A√±adido Scenario 12 (m√∫ltiples flags) para casos complejos
