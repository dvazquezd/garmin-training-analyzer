# Feature: Sistema de Cach√© Local SQLite

## Context
**Por qu√© existe**: Garmin Connect API tiene rate limits estrictos (100 requests/hora). Los usuarios ejecutan el an√°lisis m√∫ltiples veces para ajustar prompts LLM, probar configuraciones o generar reportes en diferentes formatos. Sin cache, cada ejecuci√≥n consume cuota API innecesariamente y tarda 10-30 segundos.

**Valor que aporta**:
- Reducir 90% de llamadas API a Garmin (ahorro de cuota)
- An√°lisis instant√°neo (< 1s vs 10-30s con API calls)
- Funcionamiento offline con datos recientes
- Respetar l√≠mites de Garmin autom√°ticamente
- Permitir iteraci√≥n r√°pida en desarrollo

---

## User Story
**Como** desarrollador que itera en prompts LLM o experimenta con reportes  
**Quiero** reutilizar datos de Garmin previamente descargados  
**Para** no agotar mi cuota API, acelerar el desarrollo y trabajar offline

---

## Acceptance Criteria

### Scenario 1: Primera ejecuci√≥n - crear cache vac√≠o
**Given** es la primera vez que se ejecuta el script  
**And** el directorio `.cache/` no existe  
**When** el sistema inicializa `CacheManager()`  
**Then** crea directorio `.cache/` con permisos `700` (solo owner)  
**And** crea base de datos SQLite `.cache/garmin_cache.db`  
**And** crea tabla `cache_entries` con schema:
```sql
CREATE TABLE cache_entries (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP NOT NULL,
    data_type TEXT,
    metadata TEXT
);

CREATE INDEX idx_expires_at ON cache_entries(expires_at);
```
**And** registra en log: `"üíæ Cache inicializado en .cache/garmin_cache.db"`  
**And** el archivo `.db` tiene permisos `600` (seguridad)

---

### Scenario 2: Guardar actividades en cache
**Given** el sistema descarg√≥ 15 actividades de Garmin API  
**And** configuraci√≥n: `CACHE_TTL_HOURS=24`  
**When** guarda en cache con `cache.set('activities_30days', data, ttl_hours=24)`  
**Then** serializa actividades como JSON string  
**And** inserta en `cache_entries`:
```python
{
    'key': 'activities_30days_20250130',
    'value': '[{"activityId": 123, ...}, ...]',  # JSON
    'created_at': '2025-01-30 10:00:00',
    'expires_at': '2025-01-31 10:00:00',  # +24h
    'data_type': 'activities',
    'metadata': '{"count": 15, "days": 30}'
}
```
**And** registra: `"üíæ 15 actividades guardadas en cach√© (v√°lido 24h)"`  
**And** la operaci√≥n es at√≥mica (transacci√≥n SQL)

---

### Scenario 3: Leer desde cache v√°lido
**Given** existen actividades en cache guardadas hace 10 horas  
**And** `CACHE_TTL_HOURS=24`  
**When** ejecuta `cache.get('activities_30days_20250130')`  
**Then** busca en SQLite: `SELECT value FROM cache_entries WHERE key=? AND expires_at > NOW()`  
**And** verifica que `expires_at > datetime.now(UTC)`  
**And** deserializa JSON ‚Üí Python dict  
**And** retorna datos completos  
**And** registra: `"üíæ Actividades cargadas desde cach√© (v√°lido 14h m√°s)"`  
**And** NO hace llamada a Garmin API  
**And** la operaci√≥n tarda < 100ms

---

### Scenario 4: Cache expirado - refetch y actualizar
**Given** existen actividades en cache guardadas hace 25 horas  
**And** `CACHE_TTL_HOURS=24`  
**When** ejecuta `cache.get('activities_30days_20250130')`  
**Then** detecta que `expires_at < datetime.now(UTC)`  
**And** retorna `None` (cache miss)  
**And** registra: `"üîÑ Cache expirado (25h antiguo)"`  
**And** el caller (GarminClient) hace nueva llamada a API  
**And** actualiza cache con `cache.set()` (nuevo TTL)  
**And** borra entrada expirada autom√°ticamente  
**And** registra: `"üíæ Cache actualizado (v√°lido 24h)"`

---

### Scenario 5: Desactivar cache completamente
**Given** el usuario configura:
```env
USE_CACHE=false
```
**When** ejecuta el script  
**Then** `CacheManager` se inicializa en modo disabled  
**And** `cache.get()` siempre retorna `None`  
**And** `cache.set()` NO guarda datos (no-op)  
**And** NO verifica cache SQLite  
**And** SIEMPRE hace llamadas directas a Garmin API  
**And** registra al inicio: `"‚ö†Ô∏è  Cache desactivado - usando API directamente"`

---

### Scenario 6: Limpiar cache manualmente (CLI)
**Given** el cache contiene 23 entradas (algunas expiradas)  
**When** el usuario ejecuta:
```bash
python training_analyzer.py --clear-cache
```
**Then** elimina TODAS las entradas: `DELETE FROM cache_entries`  
**And** mantiene la estructura de la BD (no borra archivo `.db`)  
**And** resetea autoincrement counters  
**And** ejecuta `VACUUM` para compactar BD  
**And** registra:
```
üóëÔ∏è  Cache limpiado completamente
   Entradas eliminadas: 23
   Espacio liberado: 1.2 MB
```
**And** contin√∫a con ejecuci√≥n normal (fetch desde API)

---

### Scenario 7: Ver estad√≠sticas del cache (debug/monitoring)
**Given** el cache contiene 50 entradas en total  
**When** el usuario ejecuta:
```bash
python -m src.cache_manager
```
**Then** calcula y muestra estad√≠sticas:
```
üìä Estad√≠sticas del Cache
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ M√©trica                    ‚îÇ Valor   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Total entries              ‚îÇ 50      ‚îÇ
‚îÇ Entries v√°lidas            ‚îÇ 35      ‚îÇ
‚îÇ Entries expiradas          ‚îÇ 15      ‚îÇ
‚îÇ Tama√±o BD (MB)             ‚îÇ 2.4     ‚îÇ
‚îÇ Antig√ºedad promedio (h)    ‚îÇ 8.3     ‚îÇ
‚îÇ Hit rate (√∫ltima hora)     ‚îÇ 87%     ‚îÇ
‚îÇ Espacio usado / disponible ‚îÇ 2.4/100 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Top 5 keys m√°s accedidos:
1. activities_30days_20250130 (15 hits)
2. body_composition_60days    (8 hits)
3. activities_60days_20250129 (5 hits)
...
```
**And** muestra breakdown por tipo de dato:
```
Por tipo:
- activities: 30 entries (1.8 MB)
- body_composition: 15 entries (0.4 MB)
- user_profile: 5 entries (0.2 MB)
```

---

### Scenario 8: Cach√© con diferentes periodos de an√°lisis (keys √∫nicas)
**Given** el usuario ejecuta an√°lisis de 30 d√≠as  
**When** llama `cache.get('activities_30days_20250130')`  
**Then** genera key √∫nica: `activities_30days_20250130`  
**And** cuando luego ejecuta an√°lisis de 60 d√≠as  
**Then** genera key diferente: `activities_60days_20250130`  
**And** ambos caches coexisten sin colisiones  
**And** cada uno tiene su TTL independiente  
**And** no se sobrescriben mutuamente

---

### Scenario 9: Corrupci√≥n de cache - recuperaci√≥n autom√°tica
**Given** el archivo `.cache/garmin_cache.db` est√° corrupto (escritura interrumpida por crash)  
**When** el sistema intenta inicializar `CacheManager()`  
**Then** detecta error SQLite: `sqlite3.DatabaseError`  
**And** registra: `"‚ö†Ô∏è  Cache corrupto detectado. Reinicializando..."`  
**And** renombra archivo corrupto: `.cache/garmin_cache.db.corrupt.TIMESTAMP`  
**And** crea nueva BD limpia  
**And** registra: `"üíæ Nuevo cache creado"`  
**And** contin√∫a ejecuci√≥n normal (fetch desde API)  
**And** NO pierde datos cr√≠ticos (solo cache temporal)

---

### Scenario 10: Limpieza autom√°tica de entradas expiradas
**Given** el cache tiene 100 entradas  
**And** 40 est√°n expiradas (antig√ºedad > TTL)  
**When** ejecuta `cache._cleanup_expired()` (autom√°tico cada hora)  
**Then** elimina solo entradas expiradas:
```sql
DELETE FROM cache_entries WHERE expires_at < datetime('now')
```
**And** registra: `"üßπ Limpieza autom√°tica: 40 entradas expiradas eliminadas"`  
**And** libera espacio en disco  
**And** mejora performance de queries  
**And** ejecuta `VACUUM` si espacio liberado > 10 MB

---

### Scenario 11: L√≠mite de tama√±o del cache (protecci√≥n)
**Given** el cache ha crecido a 95 MB  
**And** el l√≠mite configurado es `MAX_CACHE_SIZE_MB=100`  
**When** intenta guardar nueva entrada de 10 MB  
**Then** verifica tama√±o total antes de insertar  
**And** detecta que sobrepasar√≠a l√≠mite (95 + 10 > 100)  
**And** ejecuta limpieza agresiva: elimina 30% de entradas m√°s antiguas  
**And** registra:
```
‚ö†Ô∏è  Cache cerca del l√≠mite (95/100 MB)
üßπ Limpiando entradas antiguas...
üíæ Espacio liberado: 30 MB
‚úÖ Nueva entrada guardada
```
**And** contin√∫a operaci√≥n normalmente

---

### Scenario 12: Cache thread-safe (accesos concurrentes)
**Given** el usuario ejecuta 2 instancias del script simult√°neamente  
**When** ambas intentan leer/escribir cache al mismo tiempo  
**Then** SQLite maneja concurrencia con WAL mode:
```sql
PRAGMA journal_mode=WAL;
```
**And** lecturas nunca bloquean otras lecturas  
**And** escrituras esperan con timeout de 5s  
**And** NO se corrompe la BD  
**And** ambas instancias obtienen datos correctos  
**And** registra en debug: `"Lock acquired after 1.2s"`

---

## Technical Notes
- **Base de datos**: SQLite3 (stdlib Python, no requiere instalaci√≥n)
- **Serializaci√≥n**: `json.dumps()` con `ensure_ascii=False` para UTF-8
- **Timestamps**: Siempre en UTC (`datetime.utcnow()`) para evitar issues de timezone
- **Concurrencia**: 
  - `PRAGMA journal_mode=WAL` para escrituras concurrentes
  - `PRAGMA busy_timeout=5000` para retries autom√°ticos
- **Tama√±o l√≠mite**: Alertar si `.cache/` supera 100 MB (configurable)
- **√çndices**: `CREATE INDEX idx_expires_at` para queries r√°pidas
- **Seguridad**: Permisos `700` en directorio, `600` en archivo BD
- **Performance**: 
  - Inserci√≥n: ~1ms
  - Lectura: ~0.5ms
  - Limpieza de 1000 entradas: ~50ms

---

## Out of Scope
‚ùå Cache distribuido (Redis/Memcached)  
‚ùå Invalidaci√≥n selectiva por ID de actividad  
‚ùå Versionado de schema (migraciones autom√°ticas)  
‚ùå Compresi√≥n de datos (gzip/zstd) - no necesario para vol√∫menes actuales  
‚ùå Replicaci√≥n del cache entre m√°quinas  
‚ùå Cache en memoria (LRU) - SQLite ya es suficientemente r√°pido

---

## Testing Strategy
```python
# tests/test_cache.py

import pytest
from pathlib import Path
from datetime import datetime, timedelta
from src.cache_manager import CacheManager
from freezegun import freeze_time

def test_initialize_cache_first_run(tmp_path):
    """Scenario 1: Create cache"""
    cache = CacheManager(cache_dir=tmp_path)
    assert (tmp_path / 'garmin_cache.db').exists()
    # Verify schema
    result = cache._execute("SELECT name FROM sqlite_master WHERE type='table'")
    assert 'cache_entries' in [r[0] for r in result]

def test_save_and_retrieve_from_valid_cache():
    """Scenarios 2 & 3: Save/retrieve"""
    cache = CacheManager()
    test_data = [{'id': 1, 'name': 'test'}]
    
    cache.set('activities_30days', test_data, ttl_hours=24)
    retrieved = cache.get('activities_30days')
    
    assert retrieved == test_data

def test_expired_cache_returns_none():
    """Scenario 4: Expired cache"""
    cache = CacheManager()
    cache.set('old_data', {'test': 1}, ttl_hours=1)
    
    # Fast-forward time 2 hours
    with freeze_time(datetime.now() + timedelta(hours=2)):
        result = cache.get('old_data')
        assert result is None

def test_cache_disabled_bypasses_storage():
    """Scenario 5: Disabled cache"""
    cache = CacheManager(use_cache=False)
    
    cache.set('key', 'value')
    result = cache.get('key')
    
    assert result is None  # Not stored

def test_clear_cache_removes_all_entries():
    """Scenario 6: Clear cache"""
    cache = CacheManager()
    cache.set('key1', 'val1')
    cache.set('key2', 'val2')
    
    deleted_count = cache.clear()
    
    assert deleted_count == 2
    assert cache.count() == 0

def test_cache_statistics():
    """Scenario 7: Statistics"""
    cache = CacheManager()
    cache.set('key1', 'val1', ttl_hours=1)
    cache.set('key2', 'val2', ttl_hours=24)
    
    with freeze_time(datetime.now() + timedelta(hours=2)):
        stats = cache.get_statistics()
        
        assert stats['total_entries'] == 2
        assert stats['valid_entries'] == 1
        assert stats['expired_entries'] == 1

def test_different_periods_different_keys():
    """Scenario 8: Unique keys"""
    cache = CacheManager()
    
    cache.set('activities_30days_20250130', [1, 2, 3])
    cache.set('activities_60days_20250130', [4, 5, 6, 7])
    
    data30 = cache.get('activities_30days_20250130')
    data60 = cache.get('activities_60days_20250130')
    
    assert len(data30) == 3
    assert len(data60) == 4

def test_corrupted_db_reinitializes(tmp_path):
    """Scenario 9: Recovery from corruption"""
    cache_file = tmp_path / 'garmin_cache.db'
    
    # Create corrupted file
    cache_file.write_bytes(b'corrupted data not sqlite')
    
    # Initialize should handle corruption
    cache = CacheManager(cache_dir=tmp_path)
    
    # Verify new DB was created
    assert cache_file.exists()
    assert cache.count() == 0  # Empty after recovery

def test_automatic_cleanup_expired():
    """Scenario 10: Auto cleanup"""
    cache = CacheManager()
    
    # Add entries with short TTL
    for i in range(5):
        cache.set(f'key_{i}', f'val_{i}', ttl_hours=1)
    
    # Fast-forward 2 hours
    with freeze_time(datetime.now() + timedelta(hours=2)):
        deleted = cache._cleanup_expired()
        
        assert deleted == 5
        assert cache.count() == 0

def test_cache_size_limit_enforcement(tmp_path):
    """Scenario 11: Size limit"""
    cache = CacheManager(cache_dir=tmp_path, max_size_mb=1)
    
    # Try to add large data
    large_data = 'x' * 2_000_000  # 2 MB string
    
    with pytest.raises(ValueError, match="Cache size limit"):
        cache.set('large_key', large_data)

@pytest.mark.slow
def test_concurrent_access(tmp_path):
    """Scenario 12: Thread safety"""
    import threading
    
    cache = CacheManager(cache_dir=tmp_path)
    errors = []
    
    def worker(thread_id):
        try:
            for i in range(100):
                cache.set(f'key_{thread_id}_{i}', f'val_{i}')
                cache.get(f'key_{thread_id}_{i}')
        except Exception as e:
            errors.append(e)
    
    threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    
    assert len(errors) == 0  # No concurrency errors
    assert cache.count() == 500  # All entries saved
```

---

## Implementation Checklist
- [ ] Crear m√≥dulo `src/cache_manager.py`
- [ ] Implementar clase `CacheManager` con m√©todos: `get()`, `set()`, `clear()`, `count()`
- [ ] A√±adir inicializaci√≥n de BD con schema completo
- [ ] Implementar serializaci√≥n JSON (UTF-8 safe)
- [ ] Configurar WAL mode para concurrencia
- [ ] A√±adir m√©todo `get_statistics()` para monitoring
- [ ] Implementar limpieza autom√°tica de expirados
- [ ] A√±adir protecci√≥n de tama√±o m√°ximo
- [ ] Manejar corrupci√≥n con recovery autom√°tico
- [ ] Crear CLI para estad√≠sticas: `python -m src.cache_manager`
- [ ] A√±adir logging detallado (debug, info)
- [ ] Crear tests exhaustivos en `tests/test_cache.py` (12 tests)
- [ ] Documentar configuraci√≥n en README
- [ ] A√±adir ejemplos de uso

---

## Related Specs
- [Authentication](../01-authentication/garmin-auth.spec.md) - Cache reduce necesidad de re-auth
- [Activities Extraction](../02-data-extraction/activities.spec.md) - Principal consumidor del cache
- [Body Composition](../02-data-extraction/body-composition.spec.md) - Tambi√©n usa cache

---

## Changelog
- **2025-01-30**: Spec inicial creada con 12 escenarios
- **2025-01-30**: A√±adido Scenario 11 (l√≠mite de tama√±o) para prevenir crecimiento infinito
- **2025-01-30**: A√±adido Scenario 12 (thread safety) para ejecuciones concurrentes
